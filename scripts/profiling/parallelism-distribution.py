# Copyright 2023-2026 Playlab/ACAL
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Parallelism Distribution Analyzer for ACAL Simulator

This module analyzes and visualizes the parallelism characteristics of simulation
runs by processing JSON statistics files generated by the ACAL simulator. It produces
time-series visualizations showing how parallel execution degree varies across
simulation cycles.

The analyzer uses a chunking strategy to aggregate fine-grained cycle-level data into
coarser-grained time windows, making it easier to identify trends and patterns in
parallelism behavior across long simulation runs. For each chunk, it tracks both the
minimum and maximum parallel degree, providing insights into both sustained parallelism
and peak utilization.

Key Features:
    - Processes SimTopStatistic JSON data from ACAL simulator output
    - Aggregates parallel-degree metrics over configurable time windows (chunks)
    - Generates dual-line visualizations showing min/max parallelism per chunk
    - Automatically scales chunk size based on dataset size (default: 10,000 chunks)
    - Produces high-resolution output suitable for publication or detailed analysis

Typical Use Cases:
    - Analyzing parallelism bottlenecks in simulation workloads
    - Comparing parallelism characteristics across different configurations
    - Identifying phases of high/low parallelism in complex simulations
    - Validating parallel simulation algorithms and scheduler behavior

Input Format:
    The script expects JSON files with the following structure:
    {
        "SimTopStatistic": [
            {
                "tick": 0,
                "parallel-degree": 4,
                ...
            },
            {
                "tick": 1,
                "parallel-degree": 8,
                ...
            },
            ...
        ]
    }

Output Format:
    Generates PNG image files containing a line chart with:
    - X-axis: Simulation cycles (aggregated into chunks)
    - Y-axis: Parallel degree (number of concurrent operations)
    - Red line: Maximum parallel degree per chunk
    - Green line: Minimum parallel degree per chunk
    - Grid overlay for easier value reading

Usage Examples:
    Basic usage with default settings (auto-chunking to ~10,000 data points):
        $ python parallelism-distribution.py simulation_stats.json

    Specify custom output filename:
        $ python parallelism-distribution.py simulation_stats.json --output parallel_analysis.png

    Control chunking granularity (e.g., 100 cycles per chunk):
        $ python parallelism-distribution.py simulation_stats.json --chunk-size 100

    Full example with all options:
        $ python parallelism-distribution.py \\
            results/sim_stats.json \\
            --output figures/parallelism_profile.png \\
            --chunk-size 500

Expected Console Output:
    Using chunk size 500 to plot 2000 chunks
    Chart saved as figures/parallelism_profile.png

Analysis Methodology:
    The script employs a windowing approach to reduce visual noise and highlight trends:

    1. Data Loading: Reads JSON file and extracts SimTopStatistic records
    2. Sorting: Orders records by simulation tick for temporal coherence
    3. Chunking: Divides the parallel-degree time series into fixed-size windows
    4. Aggregation: Computes min/max statistics for each chunk
    5. Visualization: Plots aggregated metrics with formatted axes and legend

    The dual-line (min/max) approach reveals both:
    - Sustained parallelism: When min and max converge, parallelism is stable
    - Bursty behavior: When lines diverge, parallelism varies significantly

Performance Considerations:
    - Memory usage scales linearly with JSON file size
    - Processing time is dominated by matplotlib rendering (1-10 seconds typical)
    - For very large datasets (>10M cycles), consider increasing chunk_size
    - PNG generation uses 300 DPI for publication quality (can be reduced if needed)

Dependencies:
    - matplotlib: For plotting and visualization
    - numpy: For numerical operations and axis formatting
    - json: For parsing simulation statistics (standard library)
    - argparse: For command-line interface (standard library)
"""

import json
import argparse
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np


def plot_line_chart_from_json(filename, output_file, chunk_size=None, default_chunks=10000):
	"""Generate a line chart visualization of parallelism distribution over simulation time.

	This function reads simulation statistics from a JSON file, aggregates parallel-degree
	measurements into time-based chunks, and creates a dual-line plot showing the minimum
	and maximum parallelism within each chunk. This aggregation approach reduces visual
	clutter for long simulations while preserving critical trend information.

	The chunking strategy allows analysis of both sustained parallelism patterns and
	transient spikes. When min and max lines are close together, the simulation exhibits
	stable parallelism. When they diverge, there is significant variation in concurrent
	activity within that time window.

	Args:
		filename (str): Path to the JSON file containing SimTopStatistic data.
			The file must contain a "SimTopStatistic" key mapping to a list of
			records, where each record has at minimum "tick" and "parallel-degree" fields.
		output_file (str): Path where the generated PNG chart will be saved.
			The directory must exist; the file will be created or overwritten.
			Recommended extension: .png
		chunk_size (int, optional): Number of simulation cycles to aggregate into each
			data point on the chart. If None, automatically calculated to produce
			approximately `default_chunks` data points. For finer granularity, use
			smaller values; for coarser aggregation, use larger values.
			Default: None (auto-calculated).
		default_chunks (int, optional): Target number of chunks when chunk_size is not
			specified. The actual number may vary slightly based on total cycle count.
			Default: 10000.

	Returns:
		None: The function produces side effects (file I/O and console output) but
			does not return a value.

	Raises:
		FileNotFoundError: If the specified JSON file does not exist.
		json.JSONDecodeError: If the JSON file is malformed.
		KeyError: If the JSON structure does not contain expected keys.

	Side Effects:
		- Reads the entire JSON file into memory
		- Prints progress messages to stdout (chunk size and output filename)
		- Creates/overwrites the output PNG file
		- May display matplotlib warnings if figure dimensions are unusual

	Example:
		>>> # Analyze a simulation run with auto-chunking
		>>> plot_line_chart_from_json('sim_results.json', 'parallelism.png')
		Using chunk size 250 to plot 8000 chunks
		Chart saved as parallelism.png

		>>> # Use custom chunk size for finer granularity
		>>> plot_line_chart_from_json('sim_results.json', 'detailed.png', chunk_size=50)
		Using chunk size 50 to plot 40000 chunks
		Chart saved as detailed.png

	Implementation Details:
		The function performs the following steps:
		1. Loads and parses the JSON file
		2. Extracts SimTopStatistic records and sorts by tick
		3. Calculates optimal chunk_size if not provided
		4. Iterates through parallel-degree values in chunk-sized windows
		5. Computes min/max for each chunk
		6. Creates a matplotlib figure with dynamically scaled width
		7. Plots two lines (chunk max in red, chunk min in green)
		8. Formats axes with thousand separators and readable tick labels
		9. Saves the figure at 300 DPI resolution

	Visualization Characteristics:
		- Figure width scales with number of chunks (min 8 inches)
		- Figure height fixed at 5 inches for consistency
		- X-axis labeled to indicate cycles per data point
		- Y-axis shows raw parallel degree values
		- Grid enabled with dashed lines and 0.7 alpha for readability
		- Legend positioned in upper-right corner
		- 8 evenly-spaced x-axis tick marks with comma formatting
		- 45-degree rotation on x-axis labels to prevent overlap
	"""
	# Load data from JSON file
	with open(filename, 'r') as f:
		data = json.load(f)

	# Extract and sort data by 'tick' to ensure chronological order
	# This is critical for time-series analysis as records may not be ordered in the JSON
	records = data.get("SimTopStatistic", [])
	records.sort(key=lambda x: x["tick"])

	# Early exit if no data is available to process
	if not records:
		print("No data found.")
		return

	# Extract ticks and parallel-degree values
	# ticks serves as sequential indices (0, 1, 2, ...) for plotting purposes
	ticks = list(range(len(records)))
	# parallel_degrees contains the core metric: number of concurrent operations per cycle
	parallel_degrees = [entry["parallel-degree"] for entry in records]

	# Determine chunk size - balance between detail and visualization clarity
	# Auto-calculation: divide total cycles by target chunk count to get window size
	# The max(1, ...) ensures we never use a chunk size of zero
	if chunk_size is None:
		chunk_size = max(1, len(parallel_degrees) // default_chunks)

	# Calculate how many complete chunks we'll generate
	# Incomplete final chunk (if any) will be processed but may have fewer samples
	n_chunks = len(parallel_degrees) // chunk_size

	print(f"Using chunk size {chunk_size} to plot {n_chunks} chunks")

	# Prepare data structures for chunk-level aggregated statistics
	# chunk_midpoints: X-axis positions (chunk indices, not cycle numbers)
	# chunk_max_values: Peak parallelism observed in each chunk
	# chunk_min_values: Lowest parallelism observed in each chunk
	chunk_midpoints = []
	chunk_max_values = []
	chunk_min_values = []

	# Sliding window aggregation: process parallel_degrees in non-overlapping chunks
	for i in range(0, len(parallel_degrees), chunk_size):
		# Extract a slice of chunk_size elements (or fewer for the final chunk)
		chunk = parallel_degrees[i : i + chunk_size]
		if not chunk:
			continue
		# Compute min/max statistics for this time window
		chunk_min = min(chunk)
		chunk_max = max(chunk)

		# Store results: i // chunk_size converts cycle index to chunk index
		chunk_midpoints.append(i // chunk_size)
		chunk_max_values.append(chunk_max)
		chunk_min_values.append(chunk_min)

	# ============================================================================
	# VISUALIZATION SETUP: Create matplotlib figure with dynamic dimensions
	# ============================================================================
	# Figure width scales with data complexity (n_chunks / 500 provides good density)
	# Minimum width of 8 inches ensures readability even for small datasets
	# Fixed height of 5 inches maintains consistent aspect ratio across runs
	plt.figure(figsize=(max(n_chunks / 500, 8), 5))

	# ============================================================================
	# PLOT DUAL-LINE CHART: Maximum and minimum parallelism per chunk
	# ============================================================================
	# Red line (chunk_max_values): Shows peak parallelism within each time window
	# Useful for identifying maximum available parallelism and bursty behavior
	plt.plot(
	    chunk_midpoints,
	    chunk_max_values,
	    color='r',
	    linestyle='solid',
	    label='Chunk Max',
	    linewidth=1
	)
	# Green line (chunk_min_values): Shows lowest parallelism within each time window
	# Useful for identifying bottlenecks and sustained parallelism floors
	plt.plot(
	    chunk_midpoints,
	    chunk_min_values,
	    color='g',
	    linestyle='solid',
	    label='Chunk Min',
	    linewidth=1
	)

	# ============================================================================
	# CHART ANNOTATIONS: Labels, title, legend, and grid
	# ============================================================================
	# X-axis label clarifies that each data point represents aggregated cycles
	plt.xlabel(f"Simulated Cycle (Each Node Represents {chunk_size} Cycles)")
	# Y-axis shows the raw parallelism metric (concurrent operations)
	plt.ylabel("Parallel Degree")
	# Title provides context for the analysis being performed
	plt.title("Parallel Degree Over Time (with Chunk Min/Max)")
	# Legend positioned to avoid overlapping with typical data patterns
	plt.legend(loc="upper right")
	# Grid overlay with dashed lines and reduced opacity aids value reading
	plt.grid(True, linestyle='--', alpha=0.7)

	# ============================================================================
	# SAVE FIGURE: High-resolution output for publication/presentation
	# ============================================================================
	# 300 DPI ensures crisp rendering in papers and presentations
	# bbox_inches='tight' removes excess whitespace around the plot
	# pad_inches=0.1 adds small margin to prevent label clipping
	plt.savefig(output_file, dpi=300, bbox_inches='tight', pad_inches=0.1)

	# ============================================================================
	# AXIS FORMATTING: Configure x-axis limits and tick labels
	# ============================================================================
	# Explicitly set x-axis range to match data bounds (prevents matplotlib auto-scaling)
	plt.xlim(min(chunk_midpoints), max(chunk_midpoints))

	# Distribute 8 tick marks evenly across the x-axis for optimal readability
	# Too few ticks make interpolation difficult; too many create clutter
	num_ticks = 8
	tick_positions = np.linspace(min(chunk_midpoints), max(chunk_midpoints), num=num_ticks)

	# Apply the computed tick positions to the current axes
	plt.gca().set_xticks(tick_positions)

	# Format tick labels with thousand separators for large cycle counts
	# Lambda function converts float positions to formatted integer strings
	# Example: 12345.0 -> "12,345"
	formatter = ticker.FuncFormatter(lambda x, _: f'{int(x):,}')
	plt.gca().xaxis.set_major_formatter(formatter)

	# Rotate tick labels 45 degrees to prevent overlap with long formatted numbers
	plt.xticks(rotation=45)

	print(f"Chart saved as {output_file}")


if __name__ == "__main__":
	# ============================================================================
	# COMMAND-LINE INTERFACE: Parse arguments and execute visualization
	# ============================================================================
	# Set up argument parser with description for --help output
	parser = argparse.ArgumentParser(description="Plot a line chart from a JSON file and save it.")

	# Positional argument: Input JSON file (required)
	# Must contain SimTopStatistic data from ACAL simulator
	parser.add_argument("filename", help="Path to the JSON file")

	# Optional argument: Output filename
	# Defaults to 'output.png' in current working directory
	# User can specify custom path and filename
	parser.add_argument(
	    "--output", default="output.png", help="Output file name (default: output.png)"
	)

	# Optional argument: Manual chunk size control
	# If not specified (None), auto-calculation produces ~10,000 chunks
	# Smaller values = more detail but larger file size and longer render time
	# Larger values = less detail but faster processing and smaller file size
	parser.add_argument(
	    "--chunk-size",
	    type=int,
	    default=None,
	    help="Number of items per chunk (default: auto-split into 10,000 chunks)"
	)

	# Parse command-line arguments into args namespace object
	args = parser.parse_args()

	# Execute main visualization function with parsed arguments
	# chunk_size defaults to None if not specified, triggering auto-calculation
	plot_line_chart_from_json(args.filename, args.output, chunk_size=args.chunk_size)
